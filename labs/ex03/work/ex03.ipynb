{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Least squares and linear basis functions models\n",
    "## 1.1 Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "from numpy import linalg as LA\n",
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least squares: TODO\n",
    "    # returns mse, and optimal weights\n",
    "    # ***************************************************\n",
    "    xt = np.transpose(tx)\n",
    "    wstar = np.dot(inv(np.dot(xt,tx)),np.dot(xt,y))\n",
    "    N = y.shape[0]\n",
    "    error = (0.5/N)*LA.norm(y - np.dot(tx,wstar))\n",
    "    return wstar,error\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Here we will reuse the dataset `height_weight_genders.csv` from previous exercise section to check the correctness of your implementation. Please compare it with your previous result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from grid_search import generate_w, get_best_parameters\n",
    "\n",
    "height, weight, gender = load_data_from_ex02(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss.\n",
    "\n",
    "    You can calculate the loss using mse or mae.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    e = y - np.dot(tx,w)\n",
    "    N = y.shape[0]\n",
    "    return 0.5*np.sum(e**2) / N\n",
    "\n",
    "def grid_search(y, tx, w0, w1):\n",
    "    \"\"\"Algorithm for grid search.\"\"\"\n",
    "    losses = np.zeros((len(w0), len(w1)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    for i in range(len(w0)):\n",
    "        for j in range(len(w1)):\n",
    "            losses[i,j] =  compute_loss(y, tx, np.array([w0[i],w1[j]]))\n",
    "    # TODO: compute loss for each combination of w0 and w1.\n",
    "    # ***************************************************\n",
    "    return losses\n",
    "\n",
    "def grid_results():\n",
    "    \n",
    "    # Generate the grid of parameters to be swept\n",
    "    grid_w0, grid_w1 = generate_w(num_intervals=500)\n",
    "    # Start the grid search\n",
    "    grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "    # Select the best combinaison\n",
    "    loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "    return loss_star, w0_star, w1_star\n",
    "\n",
    "def test_your_least_squares():\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least square or grid search: TODO\n",
    "    # this code should compare the optimal weights obtained \n",
    "    # by least squares vs. grid search\n",
    "    # ***************************************************\n",
    "    wstar,error = least_squares(y, tx)\n",
    "    loss_star_g, w0_star_g, w1_star_g = grid_results()\n",
    "    print(\"Error w0 :\"+ str(abs( w0_star_g - wstar[0]) ))\n",
    "    print(\"Error w1 :\"+ str(abs( w1_star_g - wstar[1]) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error w0 :0.14762941693469145\n",
      "Error w1 :0.04734167322721916\n"
     ]
    }
   ],
   "source": [
    "test_your_least_squares()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Least squares with a linear basis function model\n",
    "Start from this section, we will use the dataset `dataEx3.csv`.\n",
    "\n",
    "### Implement polynomial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x (50,)\n",
      "shape of y (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35237491, 4.8951233 , 1.86662437, 3.50706129, 3.38087384,\n",
       "       0.73093728, 3.88562366, 5.65224803, 6.28318531, 2.37137419,\n",
       "       0.60474982, 3.63324875, 0.85712473, 2.49756165, 1.61424946,\n",
       "       5.39987312, 6.15699785, 6.0308104 , 0.47856237, 2.87612401,\n",
       "       4.51656093, 0.98331219, 1.10949964, 0.1       , 2.11899928,\n",
       "       1.36187455, 4.01181111, 5.77843549, 4.26418602, 1.2356871 ,\n",
       "       2.24518674, 1.99281183, 1.48806201, 4.64274839, 4.39037348,\n",
       "       3.00231147, 0.22618746, 5.27368567, 5.02131076, 5.52606058,\n",
       "       2.6237491 , 4.76893584, 3.12849893, 1.74043692, 3.7594362 ,\n",
       "       3.25468638, 5.90462294, 4.13799857, 2.74993656, 5.14749821])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "x, y = load_data()\n",
    "print(\"shape of x {}\".format(x.shape))\n",
    "print(\"shape of y {}\".format(y.shape))\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  4,  8],\n",
       "       [ 1,  3,  9, 27],\n",
       "       [ 1,  4, 16, 64]], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: TODO\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    # ***************************************************\n",
    "    return np.array([x**i for i in range(degree)]).T\n",
    "\n",
    "x = np.array([2,3,4])\n",
    "degree = 4\n",
    "M = build_poly(x, degree)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with polynomial regression. Note that we will use your implemented function `compute_mse`. Please copy and paste your implementation from exercise02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from costs import compute_mse\n",
    "from plots import *\n",
    "\n",
    "def polynomial_regression():\n",
    "    \"\"\"Constructing the polynomial basis function expansion of the data,\n",
    "       and then running least squares regression.\"\"\"\n",
    "    # define parameters\n",
    "    degrees = [1, 3, 7, 12]\n",
    "    \n",
    "    # define the structure of the figure\n",
    "    num_row = 2\n",
    "    num_col = 2\n",
    "    f, axs = plt.subplots(num_row, num_col)\n",
    "\n",
    "    for ind, degree in enumerate(degrees):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # form the data to do polynomial regression.: TODO\n",
    "        # ***************************************************\n",
    "        M = build_poly(x, degree)\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # least square and calculate RMSE: TODO\n",
    "        # ***************************************************\n",
    "        wstar,error = least_squares(y, M)\n",
    "        rmse = np.sqrt(2*error)\n",
    "        print(\"Processing {i}th experiment, degree={d}, rmse={loss}\".format(\n",
    "              i=ind + 1, d=degree, loss=rmse))\n",
    "        # plot fit\n",
    "        plot_fitted_curve(\n",
    "            y, x, weights, degree, axs[ind // num_col][ind % num_col])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualize_polynomial_regression\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Processing 1th experiment, degree=1, rmse=1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-88eae3953796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpolynomial_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-741c23ba6fda>\u001b[0m in \u001b[0;36mpolynomial_regression\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# plot fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         plot_fitted_curve(\n\u001b[1;32m---> 31\u001b[1;33m             y, x, weights, degree, axs[ind // num_col][ind % num_col])\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"visualize_polynomial_regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polynomial_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Evaluating model predication performance\n",
    "\n",
    "\n",
    "Let us show the train and test splits for various polynomial degrees. First of all, please fill in the function `split_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, test your `split_data` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"polynomial regression with different split ratios and different degrees.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calcualte weight through least square.: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate RMSE for train and test data,\n",
    "    # and store them in rmse_tr and rmse_te respectively: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    print(\"proportion={p}, degree={d}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "          p=ratio, d=degree, tr=rmse_tr, te=rmse_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 6\n",
    "degrees = [1, 3, 7, 12]\n",
    "split_ratios = [0.9, 0.5, 0.1]\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    for degree in degrees:\n",
    "        train_test_split_demo(x, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Ridge Regression\n",
    "Please fill in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ridge regression with a given lambda\n",
    "        # ***************************************************\n",
    "        print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               p=ratio, d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, degree)\n",
    "\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 56\n",
    "degree = 7\n",
    "split_ratio = 0.5\n",
    "ridge_regression_demo(x, y, degree, split_ratio, seed)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
